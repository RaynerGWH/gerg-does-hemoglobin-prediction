# Hemoglobin Prediction from Lip Images# Hemoglobin Prediction from Lip Images

## Project Overview## Project Overview

DSA Society Case Competition - Predicting hemoglobin levels from smartphone lip images.DSA Society Case Competition - Predicting hemoglobin levels from smartphone lip images.

**Goal:** Achieve MAE ≤ 0.8 g/dL**Goal:** Achieve MAE ≤ 0.8 g/dL

## Key Features## Setup Instructions

````bash

✨ **Enhanced Feature Extraction**# Clone repository

- Color features (RGB statistics, ratios, dominance)git clone <your-repo-url>

- Image quality metrics (brightness, contrast, blur, saturation)cd hemoglobin-prediction

- Color distribution moments (mean, std, skewness per channel)

- **28+ handcrafted features** per image# Create virtual environment

python -m venv venv

🔄 **Data Augmentation** (Training Only)source venv/bin/activate  # On Windows: venv\Scripts\activate

- Rotation, brightness/contrast adjustment

- Gaussian noise, blur, flipping# Install dependencies

- Creates 3x more training samplespip install -r requirements.txt
- Improves model generalization

🔬 **Conjunctiva Data Integration**
- Combines lip images with Kaggle anemia dataset
- Normalized feature representation
- Unified feature space for both modalities

🧠 **Optional CNN Features**
- Pre-trained ResNet18/50 or MobileNetV2
- Deep feature extraction (512-2048 dims)
- Can be combined with handcrafted features
- Works even if CNN step is skipped

📊 **Robust Model Training**
- Multiple model options (Random Forest, Gradient Boosting, Ridge)
- Feature scaling and standardization
- 5-fold cross-validation
- Feature importance analysis

## Setup Instructions

### 1. Clone Repository
```bash
git clone <your-repo-url>
cd gerg-does-hemoglobin-prediction
````

### 2. Create Virtual Environment

```bash
# Create environment
python -m venv env

# Activate environment
# On Windows:
env\Scripts\activate
# On macOS/Linux:
source env/bin/activate
```

### 3. Install Dependencies

```bash
# Core dependencies
pip install -r requirements.txt

# Optional: For CNN features (if you want deep learning)
pip install torch torchvision
```

### 4. Prepare Your Data

#### Required Directory Structure

```
data/
├── starter/
│   ├── images/              # Place your 30 test images here
│   └── labels.csv           # Generated by create_labels_csv.py
├── external/
│   └── kaggle_anemia/
│       └── anemia_dataset.csv  # Kaggle conjunctiva dataset
├── processed/               # Generated features (auto-created)
└── augmented/               # Augmented images (auto-created)
```

#### Get the Kaggle Anemia Dataset

1. Download from: https://www.kaggle.com/datasets/biswaranjanrao/anemia-detection
2. Place `anemia_dataset.csv` in `data/external/kaggle_anemia/`

## Complete Workflow

### Step 0: Create Labels CSV

```bash
cd scripts
python create_labels_csv.py
```

**Output:** `../data/starter/labels.csv` with HgB values extracted from filenames

**Expected filename format:** `HgB_10.7gdl_Individual01.heic` or `Random_11.6gdl_...`

---

### Step 1: Extract Enhanced Features

```bash
python 01_extract_enhanced_features.py
```

**What it does:**

- Extracts 28+ features from each image
- Color features: RGB percentages, ratios, dominance
- Quality metrics: brightness, contrast, blur, saturation
- Distribution: statistical moments per channel

**Output:**

- `../data/processed/enhanced_features.npy` (28 features × N images)
- `../data/processed/labels_valid.csv`
- `../data/processed/feature_names.txt`

**Time:** ~1-2 minutes for 30 images

---

### Step 2: Augment Training Data

```bash
python 02_augment_training_data.py
```

**What it does:**

- Creates 3 augmented versions per training image
- Applies random combinations of:
  - Rotation (-15° to +15°)
  - Brightness adjustment (0.8x to 1.2x)
  - Contrast adjustment (0.8x to 1.2x)
  - Saturation adjustment (0.9x to 1.1x)
  - Gaussian noise
  - Slight blur
  - Horizontal flip
  - Zoom (0.9x to 1.1x)
- Extracts features from augmented images

**Output:**

- `../data/augmented/` (augmented image files)
- `../data/processed/augmented_features.npy` (120 samples if started with 30)
- `../data/processed/augmented_labels.npy`
- `../data/processed/augmented_metadata.csv`

**Note:** Only applied to training set to prevent data leakage

**Time:** ~3-5 minutes for 30 images → 120 augmented samples

---

### Step 3: Process Conjunctiva Data

```bash
python 03_process_conjunctiva_data.py
```

**What it does:**

- Loads Kaggle anemia dataset (conjunctiva RGB data)
- Converts RGB percentages to same 28-feature format
- Estimates quality metrics from available data
- Creates normalized feature representation

**Output:**

- `../data/processed/conjunctiva_features.npy` (~1,500+ samples)
- `../data/processed/conjunctiva_labels.npy`

**Note:** Conjunctiva features are normalized to match lip image feature space

**Time:** ~10-30 seconds

---

### Step 4: Extract CNN Features (OPTIONAL)

```bash
# Option A: Use CNN features (requires PyTorch)
python 04_extract_cnn_features.py --model resnet18

# Option B: Skip CNN features (pipeline continues with handcrafted features only)
python 04_extract_cnn_features.py --skip-cnn

# Option C: Try different CNN models
python 04_extract_cnn_features.py --model resnet50
python 04_extract_cnn_features.py --model mobilenet_v2
```

**What it does:**

- Loads pre-trained CNN (ResNet18/50 or MobileNetV2)
- Extracts deep features from images
- ResNet18: 512 features per image
- ResNet50: 2,048 features per image
- MobileNetV2: 1,280 features per image

**Output:**

- `../data/processed/cnn_features_<model>.npy`
- `../data/processed/cnn_valid_indices_<model>.npy`

**Requirements:** PyTorch (`pip install torch torchvision`)

**Notes:**

- CNN features can improve performance but are optional
- If skipped, the pipeline continues with handcrafted features only
- CNN features add to training time but may improve accuracy

**Time:**

- Without GPU: ~5-10 minutes for 30 images
- With GPU: ~1-2 minutes for 30 images

---

### Step 5: Train Combined Model

```bash
# Option A: Train with all features (augmentation + conjunctiva)
python 05_train_combined_model.py --model rf

# Option B: Train with CNN features
python 05_train_combined_model.py --model rf --use-cnn --cnn-model resnet18

# Option C: Train without augmentation
python 05_train_combined_model.py --model rf --no-augmentation

# Option D: Try Gradient Boosting
python 05_train_combined_model.py --model gb

# Option E: Try Ridge Regression
python 05_train_combined_model.py --model ridge
```

**What it does:**

- Loads augmented lip features + conjunctiva features
- Optionally adds CNN features
- Standardizes all features
- Trains model with 5-fold cross-validation
- Reports CV performance
- Saves trained model

**Model Options:**

- `rf`: Random Forest (default, robust, interpretable)
- `gb`: Gradient Boosting (often higher accuracy)
- `ridge`: Ridge Regression (fast, linear baseline)

**Output:**

- `../weights/final_model.pkl` (trained model)
- `../weights/feature_scaler.pkl` (standardization scaler)
- `../weights/model_config.txt` (configuration info)

**Training data:**

- Augmented lip images: 120 samples (if 30 originals × 4)
- Conjunctiva data: ~1,500 samples
- **Total: ~1,620 samples**

**Time:**

- Random Forest: ~30-60 seconds
- Gradient Boosting: ~1-3 minutes
- With CNN features: +50% more time

---

### Step 6: Evaluate on Test Set

```bash
python 06_evaluate_on_test.py
```

**What it does:**

- Loads trained model and scaler
- Extracts features from 30 test images
- Makes predictions
- Calculates MAE, RMSE, R²
- Creates visualization
- Saves detailed results

**Output:**

- `../results/test_evaluation.csv` (predictions + errors)
- `../results/test_evaluation_plot.png` (scatter plot)
- Console output with metrics

**Metrics:**

- **MAE** (Mean Absolute Error): Target ≤ 0.8 g/dL
- **RMSE** (Root Mean Square Error): Overall error magnitude
- **R²** (R-squared): How well predictions fit actual values

**Time:** ~30-60 seconds

---

## Complete Pipeline Execution

### Quick Start (All Steps)

```bash
cd scripts

# Step 0: Create labels
python create_labels_csv.py

# Step 1: Extract features
python 01_extract_enhanced_features.py

# Step 2: Augment data
python 02_augment_training_data.py

# Step 3: Process conjunctiva
python 03_process_conjunctiva_data.py

# Step 4: (Optional) Extract CNN features
python 04_extract_cnn_features.py --skip-cnn
# OR with CNN: python 04_extract_cnn_features.py --model resnet18

# Step 5: Train model
python 05_train_combined_model.py --model rf

# Step 6: Evaluate
python 06_evaluate_on_test.py
```

**Total Time:**

- Without CNN: ~5-8 minutes
- With CNN (no GPU): ~15-20 minutes
- With CNN (GPU): ~7-10 minutes

---

## Understanding the Features

### Basic Color Features (13)

1. **RGB Percentages** (3): Absolute color distribution
2. **RGB Ratios** (3): Relative proportions (lighting-independent)
3. **Color Ratios** (3): R/G, R/B, G/B (anemia indicators)
4. **Red Dominance** (1): R - B (higher in healthy individuals)
5. **Normalized RGB** (3): 0-1 scale values

### Image Quality Features (5)

1. **Brightness**: Average pixel intensity
2. **Contrast**: Standard deviation of intensity
3. **Blur Score**: Laplacian variance (sharpness)
4. **Saturation**: HSV saturation mean
5. **Lighting Uniformity**: Consistency of illumination

### Extended Color Features (1)

1. **Redness Index**: (R-G)/(R+G) for anemia detection

### Color Distribution Moments (9)

1. **Per-channel statistics** (R, G, B × 3 each):
   - Mean: Average channel value
   - Std: Channel variability
   - Skewness: Distribution asymmetry

**Total: 28 handcrafted features**

### CNN Features (Optional)

- ResNet18: 512 deep features
- ResNet50: 2,048 deep features
- MobileNetV2: 1,280 deep features

---

## Data Augmentation Details

### Why Augmentation?

- **Small dataset problem**: 30 images is very small for ML
- **Prevent overfitting**: Model learns general patterns, not specific images
- **Simulate real-world variation**: Different lighting, angles, noise

### Augmentation Techniques Applied

1. **Geometric**: Rotation, zoom
2. **Photometric**: Brightness, contrast, saturation
3. **Noise**: Gaussian noise, blur
4. **Spatial**: Horizontal flip

### Augmentation Strategy

- Applied **ONLY to training set** (prevents data leakage)
- Creates 3 augmented versions per image
- Each augmented image gets 2-4 random transforms
- Features extracted from augmented images

---

## Model Selection Guide

### Random Forest (rf) - **Recommended**

✅ **Pros:**

- Robust to outliers
- Handles non-linear relationships
- Feature importance analysis
- No feature scaling required (but we do it anyway)
- Fast training and prediction

❌ **Cons:**

- Can overfit with small datasets (mitigated by augmentation)
- Slower than linear models

**Best for:** General use, interpretability

---

### Gradient Boosting (gb)

✅ **Pros:**

- Often highest accuracy
- Handles complex patterns
- Good with mixed feature types

❌ **Cons:**

- Slower training
- More prone to overfitting
- Less interpretable

**Best for:** Maximum performance

---

### Ridge Regression (ridge)

✅ **Pros:**

- Very fast
- Simple and interpretable
- Regularization prevents overfitting

❌ **Cons:**

- Assumes linear relationships
- May underperform with complex patterns

**Best for:** Baseline, quick experiments

---

## Troubleshooting

### Issue: "Labels file not found"

**Solution:** Run `create_labels_csv.py` first to generate labels from filenames

### Issue: "Kaggle dataset not found"

**Solution:** Download anemia dataset and place in `data/external/kaggle_anemia/`

### Issue: "PyTorch not installed" (for CNN)

**Solution:** Either install PyTorch (`pip install torch torchvision`) or skip CNN with `--skip-cnn`

### Issue: Low accuracy (MAE > 0.8)

**Try:**

1. Use Gradient Boosting: `--model gb`
2. Add CNN features: `--use-cnn --cnn-model resnet50`
3. Check data quality (blur, lighting)
4. Verify feature extraction is working correctly

### Issue: "Out of memory" with CNN

**Solution:** Use smaller model (`mobilenet_v2`) or skip CNN features

---

## Project Structure

```
gerg-does-hemoglobin-prediction/
├── README.md                      # This file
├── requirements.txt               # Python dependencies
│
├── data/
│   ├── starter/
│   │   ├── images/               # 30 test images
│   │   └── labels.csv            # Generated labels
│   ├── external/
│   │   └── kaggle_anemia/
│   │       └── anemia_dataset.csv  # Conjunctiva data
│   ├── processed/                # Generated features
│   │   ├── enhanced_features.npy
│   │   ├── augmented_features.npy
│   │   ├── conjunctiva_features.npy
│   │   ├── cnn_features_*.npy (optional)
│   │   └── labels_*.csv
│   └── augmented/                # Augmented images
│
├── scripts/
│   ├── create_labels_csv.py                    # Step 0
│   ├── 01_extract_enhanced_features.py         # Step 1
│   ├── 02_augment_training_data.py             # Step 2
│   ├── 03_process_conjunctiva_data.py          # Step 3
│   ├── 04_extract_cnn_features.py              # Step 4 (optional)
│   ├── 05_train_combined_model.py              # Step 5
│   └── 06_evaluate_on_test.py                  # Step 6
│
├── weights/
│   ├── final_model.pkl           # Trained model
│   ├── feature_scaler.pkl        # Feature standardization
│   └── model_config.txt          # Model configuration
│
└── results/
    ├── test_evaluation.csv       # Detailed predictions
    └── test_evaluation_plot.png  # Visualization
```

---

## Performance Tips

### For Best Results:

1. ✅ Use data augmentation (default)
2. ✅ Include conjunctiva data (default)
3. ✅ Try Gradient Boosting model
4. ✅ Add CNN features if time permits
5. ✅ Ensure high-quality input images (sharp, well-lit)

### For Faster Training:

1. ⚡ Use Random Forest (default)
2. ⚡ Skip CNN features (`--skip-cnn`)
3. ⚡ Reduce augmentation (edit script to create fewer versions)

---

## Expected Performance

### Baseline (30 images only, no augmentation):

- **MAE:** ~1.2-1.5 g/dL
- **Problem:** Overfitting, insufficient data

### With Augmentation + Conjunctiva:

- **MAE:** ~0.7-0.9 g/dL
- **Result:** Usually meets target ✅

### With Augmentation + Conjunctiva + CNN:

- **MAE:** ~0.6-0.8 g/dL
- **Result:** Best performance ✅

---

## References

### Datasets

- Genesis lip images: 30 test images
- Kaggle Anemia Dataset: https://www.kaggle.com/datasets/biswaranjanrao/anemia-detection

### Libraries

- scikit-learn: ML models
- OpenCV: Image processing
- PyTorch: Deep learning (optional)
- Pillow: Image loading

---

## Contact

For questions or issues, please contact the project maintainer.

**Target:** MAE ≤ 0.8 g/dL 🎯

Good luck! 🚀
